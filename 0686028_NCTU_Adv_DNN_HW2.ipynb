{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"0686028_NCTU_Adv_DNN_HW2.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1kmjKqC92cuqIFsp8JnNoOmNeM92YsTa7","authorship_tag":"ABX9TyPW2iLe6/O/DMC3MI7K9eCU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iaFJcDIO6MG9","executionInfo":{"status":"ok","timestamp":1605923151118,"user_tz":-480,"elapsed":6276,"user":{"displayName":"王啟龍","photoUrl":"","userId":"01401139107177574945"}},"outputId":"29ee3231-5ff9-4bd8-d9b0-8513df997565"},"source":["from google_drive_downloader import GoogleDriveDownloader as gdd\n","    \n","if 'google.colab' in str(get_ipython()):\n","    print('Running on CoLab')\n","    %cd /content\n","    !rm -r /content/chilung-NCTU_Adv_DNN_HW2_2\n","    !rm /content/test.zip\n","    !rm -r /content/test\n","    !git clone https://github.com/chilung/chilung-NCTU_Adv_DNN_HW2_2.git\n","    !mv /content/chilung-NCTU_Adv_DNN_HW2_2/* .\n","    !rm -r /content/chilung-NCTU_Adv_DNN_HW2_2\n","    gdd.download_file_from_google_drive(file_id='1nswVLQSGupsRympzb3tUv3L94d7ADPmi',\n","                dest_path='./test.zip',\n","                unzip=True)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Running on CoLab\n","/content\n","rm: cannot remove '/content/chilung-NCTU_Adv_DNN_HW2_2': No such file or directory\n","rm: cannot remove '/content/test.zip': No such file or directory\n","rm: cannot remove '/content/test': No such file or directory\n","Cloning into 'chilung-NCTU_Adv_DNN_HW2_2'...\n","remote: Enumerating objects: 3, done.\u001b[K\n","remote: Counting objects: 100% (3/3), done.\u001b[K\n","remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n","Unpacking objects: 100% (3/3), done.\n","Downloading 1nswVLQSGupsRympzb3tUv3L94d7ADPmi into ./test.zip... Done.\n","Unzipping...Done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"MS7F8H9seWhS"},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-B-wHoEJ40ao","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605895275121,"user_tz":-480,"elapsed":6375,"user":{"displayName":"王啟龍","photoUrl":"","userId":"01401139107177574945"}},"outputId":"9b330898-4f04-4b01-8c74-72404303cd17"},"source":["from google.colab import drive\n","if 'google.colab' in str(get_ipython()):\n","    print('Running on CoLab')\n","    %cd /content\n","    !rm -r /content/test\n","    !rm /content/test.zip\n","    !git clone https://github.com/chilung/chilung-NCTU_Adv_DNN_HW2_2.git\n","    !mv /content/chilung-NCTU_Adv_DNN_HW2_2 .\n","    drive.mount('/content/drive/')\n","    !cp -r '/content/drive/MyDrive/Colab Notebooks/NCTU_Adv_DNN_HW2/'* /content\n","    !unzip /content/exec_env/test.zip >/dev/null\n","else:\n","    print('Not running on CoLab')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Running on CoLab\n","/content\n","rm: cannot remove '/content/test.zip': No such file or directory\n","Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"np-45U67yetH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1605896126414,"user_tz":-480,"elapsed":855007,"user":{"displayName":"王啟龍","photoUrl":"","userId":"01401139107177574945"}},"outputId":"f483d81d-f020-40a2-dfd3-618f7f1b6115"},"source":["# -*- coding: utf-8 -*-\n","'''\n","@Time          : 20/04/25 15:49\n","@Author        : huguanghao\n","@File          : demo.py\n","@Noice         :\n","@Modificattion :\n","    @Author    :\n","    @Time      :\n","    @Detail    :\n","'''\n","\n","import os\n","from tool.utils import *\n","from tool.torch_utils import *\n","from tool.darknet2pytorch import Darknet\n","import argparse\n","import cv2\n","import time\n","import datetime\n","import json\n","import numpy as np\n","\n","\"\"\"hyper parameters\"\"\"\n","use_cuda = True\n","\n","def output_transform(img_width, img_height, rel_center_x, rel_center_y, rel_width, rel_height):\n","    center_x = rel_center_x * img_width\n","    center_y = rel_center_y * img_height\n","    width = rel_width * img_width\n","    height = rel_height * img_height\n","    return (int(round(center_y-height/2)), int(round(center_x-width/2)), int(round(center_y+height/2)), int(round(center_x+width/2)))\n","\n","def detect_cv2(cfgfile, weightfile, imgfiles, namesfile):\n","    CENTER_X = 0\n","    CENTER_Y = 1\n","    WIDTH = 2\n","    HEIGHT = 3\n","    CONFIDENCE = 4\n","    CLASS_ID = 6\n","    \n","    m = Darknet(cfgfile)\n","\n","    # m.print_network()\n","    m.load_weights(weightfile)\n","    print('Loading weights from %s... Done!' % (weightfile))\n","\n","    if use_cuda:\n","        m.cuda()\n","\n","    num_classes = m.num_classes\n","    class_names = load_class_names(namesfile)\n","\n","    f = open(imgfiles, 'r')\n","    filelist = f.read().splitlines()\n","    f.close()\n","    # print(filelist)\n","    \n","    print(time.ctime())\n","    start_time = time.time()\n","\n","    submit_results = []\n","    for idx, imgfile in enumerate(filelist):\n","        # print(imgfile)\n","        img = cv2.imread(imgfile)\n","        sized = cv2.resize(img, (m.width, m.height))\n","        sized = cv2.cvtColor(sized, cv2.COLOR_BGR2RGB)\n","        img_height, img_width, _ = img.shape\n","\n","        predict = do_detect(m, sized, 0.2, 0.6, use_cuda)[0]\n","        if idx%100 == 0:\n","            print('predict img proceed: {}'.format(idx))\n","\n","        result = {}\n","        result['bbox'] = [\n","            output_transform(\n","                img_width, img_height,\n","                box[CENTER_X], box[CENTER_Y],\n","                box[WIDTH], box[HEIGHT])\n","            for box in predict]\n","        # print(result['bbox'])\n","        result['score'] = [float(box[CONFIDENCE]) for box in predict]\n","        # print(result['score'])\n","        result['label'] = [int(box[CLASS_ID]) if not box[CLASS_ID]==0 else 10 for box in predict]\n","        # print(result['label'])\n","        # print(result)\n","        submit_results.append(result)\n","\n","    end_time = time.time()\n","    print(time.ctime())\n","    print(end_time, start_time)\n","    print('number of predicts: {}, fps: {}'.format(len(submit_results), len(submit_results)/(end_time-start_time)))\n","\n","    print('output results for submission: {}'.format('submission.json'))\n","    with open('submission.json', 'w') as outfile:\n","       json.dump(submit_results, outfile)\n","\n","    # plot_boxes_cv2(img, boxes[0], savename='predictions.jpg', class_names=class_names)\n","\n","def get_args():\n","    parser = argparse.ArgumentParser('Test your image or video by trained model.')\n","    parser.add_argument('-cfgfile', type=str, default='./exec_env/yolo-obj.cfg',\n","                        help='path of cfg file', dest='cfgfile')\n","    parser.add_argument('-weightfile', type=str,\n","                        default='./exec_env/yolo-obj-mAP_93.3.weights',\n","                        help='path of trained model.', dest='weightfile')\n","    parser.add_argument('-imgfiles', type=str,\n","                        default='./exec_env/valid.txt',\n","                        help='path of your image file directory.', dest='imgfiles')\n","    parser.add_argument('-namesfile', type=str,\n","                        default='./exec_env/obj.names',\n","                        help='path of your name file.', dest='namesfile')\n","    args = parser.parse_args(args=['-cfgfile', './exec_env/yolo-obj.cfg',\n","                    '-weightfile', './exec_env/yolo-obj-mAP_93.3.weights',\n","                    '-imgfiles', './exec_env/valid.txt',\n","                    '-namesfile', './exec_env/obj.names'])\n","    print(args)\n","    # args = parser.parse_args()\n","\n","    return args\n","\n","if __name__ == '__main__':\n","    args = get_args()\n","    if args.imgfiles:\n","        detect_cv2(args.cfgfile, args.weightfile, args.imgfiles, args.namesfile)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Namespace(cfgfile='./exec_env/yolo-obj.cfg', imgfiles='./exec_env/valid.txt', namesfile='./exec_env/obj.names', weightfile='./exec_env/yolo-obj-mAP_93.3.weights')\n","convalution havn't activate linear\n","convalution havn't activate linear\n","convalution havn't activate linear\n","Loading weights from ./exec_env/yolo-obj-mAP_93.3.weights... Done!\n","Fri Nov 20 18:01:15 2020\n","predict img proceed: 0\n","predict img proceed: 100\n","predict img proceed: 200\n","predict img proceed: 300\n","predict img proceed: 400\n","predict img proceed: 500\n","predict img proceed: 600\n","predict img proceed: 700\n","predict img proceed: 800\n","predict img proceed: 900\n","predict img proceed: 1000\n","predict img proceed: 1100\n","predict img proceed: 1200\n","predict img proceed: 1300\n","predict img proceed: 1400\n","predict img proceed: 1500\n","predict img proceed: 1600\n","predict img proceed: 1700\n","predict img proceed: 1800\n","predict img proceed: 1900\n","predict img proceed: 2000\n","predict img proceed: 2100\n","predict img proceed: 2200\n","predict img proceed: 2300\n","predict img proceed: 2400\n","predict img proceed: 2500\n","predict img proceed: 2600\n","predict img proceed: 2700\n","predict img proceed: 2800\n","predict img proceed: 2900\n","predict img proceed: 3000\n","predict img proceed: 3100\n","predict img proceed: 3200\n","predict img proceed: 3300\n","predict img proceed: 3400\n","predict img proceed: 3500\n","predict img proceed: 3600\n","predict img proceed: 3700\n","predict img proceed: 3800\n","predict img proceed: 3900\n","predict img proceed: 4000\n","predict img proceed: 4100\n","predict img proceed: 4200\n","predict img proceed: 4300\n","predict img proceed: 4400\n","predict img proceed: 4500\n","predict img proceed: 4600\n","predict img proceed: 4700\n","predict img proceed: 4800\n","predict img proceed: 4900\n","predict img proceed: 5000\n","predict img proceed: 5100\n","predict img proceed: 5200\n","predict img proceed: 5300\n","predict img proceed: 5400\n","predict img proceed: 5500\n","predict img proceed: 5600\n","predict img proceed: 5700\n","predict img proceed: 5800\n","predict img proceed: 5900\n","predict img proceed: 6000\n","predict img proceed: 6100\n","predict img proceed: 6200\n","predict img proceed: 6300\n","predict img proceed: 6400\n","predict img proceed: 6500\n","predict img proceed: 6600\n","predict img proceed: 6700\n","predict img proceed: 6800\n","predict img proceed: 6900\n","predict img proceed: 7000\n","predict img proceed: 7100\n","predict img proceed: 7200\n","predict img proceed: 7300\n","predict img proceed: 7400\n","predict img proceed: 7500\n","predict img proceed: 7600\n","predict img proceed: 7700\n","predict img proceed: 7800\n","predict img proceed: 7900\n","predict img proceed: 8000\n","predict img proceed: 8100\n","predict img proceed: 8200\n","predict img proceed: 8300\n","predict img proceed: 8400\n","predict img proceed: 8500\n","predict img proceed: 8600\n","predict img proceed: 8700\n","predict img proceed: 8800\n","predict img proceed: 8900\n","predict img proceed: 9000\n","predict img proceed: 9100\n","predict img proceed: 9200\n","predict img proceed: 9300\n","predict img proceed: 9400\n","predict img proceed: 9500\n","predict img proceed: 9600\n","predict img proceed: 9700\n","predict img proceed: 9800\n","predict img proceed: 9900\n","predict img proceed: 10000\n","predict img proceed: 10100\n","predict img proceed: 10200\n","predict img proceed: 10300\n","predict img proceed: 10400\n","predict img proceed: 10500\n","predict img proceed: 10600\n","predict img proceed: 10700\n","predict img proceed: 10800\n","predict img proceed: 10900\n","predict img proceed: 11000\n","predict img proceed: 11100\n","predict img proceed: 11200\n","predict img proceed: 11300\n","predict img proceed: 11400\n","predict img proceed: 11500\n","predict img proceed: 11600\n","predict img proceed: 11700\n","predict img proceed: 11800\n","predict img proceed: 11900\n","predict img proceed: 12000\n","predict img proceed: 12100\n","predict img proceed: 12200\n","predict img proceed: 12300\n","predict img proceed: 12400\n","predict img proceed: 12500\n","predict img proceed: 12600\n","predict img proceed: 12700\n","predict img proceed: 12800\n","predict img proceed: 12900\n","predict img proceed: 13000\n","Fri Nov 20 18:15:25 2020\n","1605896125.74825 1605895275.4724703\n","number of predicts: 13068, fps: 15.3691311826382\n","output results for submission: submission.json\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Qt24txiPh-Xk"},"source":["!cp submission.json '/content/drive/MyDrive/Colab Notebooks/NCTU_Adv_DNN_HW2/'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MhilLOfozj29"},"source":[""],"execution_count":null,"outputs":[]}]}